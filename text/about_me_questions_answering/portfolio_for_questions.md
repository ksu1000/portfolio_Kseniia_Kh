# Context About Kseniia

Kseniia is a passionate data scientist and machine learning enthusiast. She specializes in projects across various domains, including image processing, tabular data analysis, and natural language processing.

## 1. About Kseniia
- **Main Interests:** Machine Learning, Deep Learning, Data Science.
- **Key Skills and Tools:** Python, TensorFlow, Pandas, NumPy, Scikit-learn, Hugging Face Transformers, Optuna.
- **Notable Projects:** Pneumonia detection from chest X-rays, vegetable classification, insurance premium prediction, tweet classification.

## 2. Portfolio Structure
Kseniia organizes her work into three main categories based on the input data type:
1. **Images:** Projects involving computer vision and image processing.
2. **Tabular Data:** Analysis and modeling of structured datasets for tasks like classification and regression.
3. **Text:** Natural language processing projects, including text classification and sentiment analysis.

### Tools Used in Projects
- **Data Analysis and Visualization:** Pandas, NumPy, Matplotlib, Seaborn.
- **Model Development:** TensorFlow, Scikit-learn, Hugging Face Transformers.
- **Hyperparameter Optimization:** Optuna.

## 3. Completed Projects
### Image Projects
1. **Pneumonia Segmentation:** 
   - A multitask learning project for segmenting and classifying pneumonia from chest X-ray images.
   - Techniques: U-Net, residual blocks, multimodal data with late fusion, custom loss function.
2. **Vegetable Classification:**
   - A project for classifying vegetables using image data.
   - Techniques: Transfer learning, MobileNet, data augmentation, fine-tuning.

### Tabular Data Projects
1. **Insurance Premium Prediction:** 
   - Regression to predict insurance premiums based on customer attributes.
   - Techniques: Feature engineering, missing data imputation, log transformations, LGBMRegressor, pipelines.

### Text Projects
1. **Tweet Classification:**
   - Binary classification of tweets into disaster or non-disaster categories.
   - Techniques: Data cleaning, tokenization, fine-tuning DistilBERT, confusion matrices, classification reports.




